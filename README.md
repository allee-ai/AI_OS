# Nola: Local-First Personal AI with Hierarchical Context

A privacy-first, open-source personal AI system with **Hierarchical Experiential Attention (HEA)**, persistent memory, and multi-channel stimuli support. Nola is not just a chat appâ€”she is a context-aware, extensible cognitive agent that runs entirely on your machine.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![Node](https://img.shields.io/badge/node-18+-green.svg)

---

## ğŸ§  Why Nola?

- **Not just a chatbot:** Nola is a local-first, privacy-respecting AI with a persistent, hierarchical memory system.
- **Hierarchical Context:** Every message is classified and routed through a context manager (HEA) that dynamically adjusts how much of your identity and history is used.
- **User-owned data:** All conversations and identity data are stored locallyâ€”never in the cloud.
- **Multi-channel:** React chat is just one stimuli channel. CLI, email, and more are supported or planned.
- **Research + Product:** Designed for both everyday use and as a platform for AI/UX research.

---

## ğŸš€ Quick Start

### 1. One-Command Start (Recommended)

**macOS/Linux:**
```bash
git clone https://github.com/allee-ai/AI_OS.git
cd AI_OS
chmod +x start.sh
./start.sh
```

**Windows:**
```cmd
git clone https://github.com/allee-ai/AI_OS.git
cd AI_OS
start.bat
```

The script will:
1. Check/install prerequisites (Ollama, Python, Node)
2. Start Ollama if needed
3. Install dependencies
4. Start backend & frontend
5. Open browser automatically

### 2. Docker

```bash
ollama serve  # Ensure Ollama is running on host
chmod +x start-docker.sh
./start-docker.sh
```

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STIMULI CHANNELS                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  React Chat  â”‚    Twilio    â”‚    Email     â”‚   CLI     â”‚
â”‚  (this app)  â”‚   (future)   â”‚   (future)   â”‚ (exists)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              NOLA - Hierarchical State                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Context Manager (HEA)                                 â”‚
â”‚  â”œâ”€â”€ L1: Realtime (~10 tokens) - Quick responses       â”‚
â”‚  â”œâ”€â”€ L2: Conversational (~50 tokens) - Default         â”‚
â”‚  â””â”€â”€ L3: Analytical (~200 tokens) - Deep context       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Identity Thread                                      â”‚
â”‚  â”œâ”€â”€ machineID.json â†’ identity.json â†’ Nola.json        â”‚
â”‚  â””â”€â”€ userID.json â”€â”€â”˜                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Ollama (Local LLM)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

- **Hierarchical Context (HEA):** L1/L2/L3 context levels, automatic escalation based on message type
- **Persistent Memory:** All conversations and identity data are stored in `Nola/Stimuli/conversations/`
- **Local AI:** Powered by Ollama (runs entirely on your machine)
- **Multi-channel:** React, CLI, and more
- **Modern Stack:** React 18 + TypeScript + Vite + FastAPI
- **User-Owned Data:** Your conversations, your machine, no cloud

---

## ğŸ“ Project Structure

```
React_Demo/
â”œâ”€â”€ Nola/                    # ğŸ§  The brain - hierarchical state system
â”‚   â”œâ”€â”€ agent.py            # Thread-safe singleton agent
â”‚   â”œâ”€â”€ contract.py         # Metadata protocol
â”‚   â”œâ”€â”€ Nola.json           # Global runtime state
â”‚   â”œâ”€â”€ identity_thread/    # Identity hierarchy
â”‚   â”‚   â”œâ”€â”€ identity.json   # Aggregated identity
â”‚   â”‚   â”œâ”€â”€ machineID/      # Machine context module
â”‚   â”‚   â””â”€â”€ userID/         # User context module
â”‚   â””â”€â”€ Stimuli/
â”‚       â”œâ”€â”€ conversations/  # ğŸ’¬ Chat history stored here
â”‚       â””â”€â”€ comms/          # Future: Twilio, email modules
â”‚
â”œâ”€â”€ react-chat-app/         # ğŸ’» This stimuli channel
â”‚   â”œâ”€â”€ backend/            # FastAPI server
â”‚   â”‚   â”œâ”€â”€ main.py         # App entry point
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ agent_service.py  # â­ Nola integration + HEA
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ chat.py     # REST endpoints
â”‚   â”‚       â””â”€â”€ websockets.py
â”‚   â””â”€â”€ frontend/           # React + Vite app
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ components/Chat/
â”‚           â”œâ”€â”€ hooks/
â”‚           â””â”€â”€ services/
â”‚
â”œâ”€â”€ docs/                   # ğŸ“š Theory & evaluation
â”‚   â”œâ”€â”€ concept_attention_theory.md
â”‚   â””â”€â”€ tests.md
â”‚
â””â”€â”€ .github/               # ğŸ‘¥ Contributor infrastructure
    â”œâ”€â”€ agents/            # AI agent profiles
    â””â”€â”€ ISSUE_TEMPLATE/
```

---

## ğŸ§© Key Concepts

- **Stimuli Channel:** Any interface (chat, CLI, email, etc.) that sends messages to Nolaâ€™s cognitive system.
- **Identity Thread:** Aggregates machine and user identity, filters by context level.
- **Context Manager (HEA):** Classifies each message and selects the right context depth.
- **Persistence:** All chat and identity data is stored locally for privacy and continuity.

---

## ğŸ› ï¸ Development & API

### Backend

```bash
cd backend
uvicorn main:app --reload --port 8000
# API docs at http://localhost:8000/docs
```

### Frontend

```bash
cd frontend
npm run dev      # Development server
npm run build    # Production build
npm run preview  # Preview production build
```

### Type Checking

```bash
cd frontend
npm run build  # Runs TypeScript compiler
```

---

## ğŸ“¦ Building for Production

### Docker

```bash
docker-compose up --build
```

### Manual Build

```bash
# Backend - runs as-is with uvicorn
cd backend
uvicorn main:app --host 0.0.0.0 --port 8000

# Frontend - build static files
cd frontend
npm run build
# Serve dist/ with any static server
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai) - Local LLM runtime
- [FastAPI](https://fastapi.tiangolo.com) - Modern Python web framework
- [Vite](https://vitejs.dev) - Next-gen frontend tooling
- [React](https://react.dev) - UI library
