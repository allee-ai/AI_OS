# Nola — 认知操作系统框架

> **状态:** 积极开发中。寻求合作者与支持。

## 核心理念

Nola 不是聊天机器人，而是一个**认知操作系统**——一个开源框架，赋予任意大模型持久身份、分层记忆，以及通过经验成长而非重新训练的能力。

**核心洞察:** 结构胜过规模。一个具备合理认知架构的 7B 模型，能够在人格一致性和上下文相关性上超越 100B 的扁平上下文模型。

## 特性

### HEA — 分层体验注意力

传统大模型使用扁平注意力——O(N²) 复杂度。随着上下文增长，噪声呈二次方增长。

Nola 的 HEA 使用分层上下文——O(k·c²) 复杂度：
- **L1 核心:** 身份、当前目标（始终加载）
- **L2 工作:** 近期对话、临时事实
- **L3 参考:** 长期记忆、用户偏好（按需调用）

```
标准 RAG:      100,000 tokens → 10,000,000,000 注意力运算
Nola HEA:     10 线程 × 200 tokens → 400,000 运算
```

### 潜意识模块

每次响应前组装上下文：
- **身份线程:** 核心人格、名称、目标
- **记忆线程:** 学习到的事实、对话历史
- **日志线程:** 事件时间线、会话追踪
- **哲学线程:** (规划中) 伦理约束、边界

### 状态管理

- SQLite 数据库后端
- 睡眠/唤醒周期进行状态整合
- 事实评分与晋升系统
- 持久身份（无需重新训练）

## 快速开始

### 前置条件

- Python 3.11+
- Node.js 18+
- Ollama（用于本地模型）

### 一键启动

```bash
git clone https://github.com/your-username/AI_OS.git
cd AI_OS
./start.sh
```

脚本会自动：
1. 检测操作系统（macOS / Linux / Windows WSL）
2. 启动 Ollama 并拉取模型
3. 安装 Python 和 Node 依赖
4. 启动后端（FastAPI）和前端（React + Vite）
5. 打开浏览器到 http://localhost:5173

按 `Ctrl+C` 可优雅关闭所有服务。

## 架构

```
┌─────────────────────────────────────────────────────────────────┐
│                    用户输入 / 触发器                              │
│              (聊天、邮件、日历、文件变更、定时器)                  │
└────────────────────────────┬────────────────────────────────────┘
                             ▼
┌─────────────────────────────────────────────────────────────────┐
│                      潜意识模块                                   │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐           │
│  │ 身份线程  │ │ 记忆线程  │ │ 日志线程 │ │ 哲学线程  │           │
│  └────┬─────┘ └────┬─────┘ └────┬─────┘ └────┬─────┘           │
│       └────────────┴────────────┴────────────┘                  │
│                         │                                        │
│              get_consciousness_context(level)                    │
└────────────────────────┬────────────────────────────────────────┘
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│                    大模型推理                                     │
│              (Qwen / Claude / GPT / 等)                          │
└────────────────────────┬────────────────────────────────────────┘
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│                    响应 / 动作                                    │
└─────────────────────────────────────────────────────────────────┘
```

## 评测

内置对抗一致性测试：

```bash
# Nola vs 原始大模型对决
python eval/coherence_test.py --turns 8 --opponent "gpt-oss:20b-cloud"

# AI vs AI 身份保持对战
python eval/ai_battle.py --turns 50 --adversary "gpt-oss:120b-cloud" --judge "kimi-k2:1t-cloud"
```

初步结果：Nola (7B + HEA) 在人格一致性评分上 **16.75 vs 14.88** 击败原始 20B 模型。

## 路线图

完整路线图见 [ROADMAP.md](ROADMAP.md)。

| 阶段 | 状态 | 描述 |
|------|------|------|
| 潜意识模块 | ✅ 完成 | 响应前组装上下文 |
| 线程适配器 | ✅ 完成 | 可插拔架构 |
| HEA 上下文层级 | ✅ 完成 | L1/L2/L3 动态过滤 |
| 记忆整合 | 🔄 进行中 | 事实评分与晋升 |
| 哲学线程 | 📋 计划中 | 伦理、边界、决心 |
| 反射线程 | 📋 计划中 | 模式 → 自动化 |
| 梦境状态 | 📋 计划中 | 通过合成体验发展人格 |

## 核心论点

> "结构胜过规模。"

大多数 AI 框架将大模型视为无状态计算器。发送提示，获取响应，遗忘一切。

Nola 将大模型视为**推理引擎**，运行于**结构化现实**之上。身份持久化。记忆整合。反射自动化。哲学约束。

这不是通用人工智能。这是**持久人工智能**——一个真正与用户共同成长的 AI。

## 寻求合作

### 我正在寻找：

**合作者**
- 熟悉 async/状态管理的 Python 开发者
- React UI 改进的前端开发者
- 对认知架构感兴趣的 AI 研究者

**支持**
- 这是一个业余时间的个人项目
- 有资源支持的话，路线图可以在数月内完成，而非数年
- 欢迎讨论资金、合作或就业机会

## 许可证

MIT — 见 [LICENSE](LICENSE)

## 联系方式

- **GitHub Issues:** 功能请求、Bug 报告
- **项目:** https://github.com/your-username/AI_OS

---

*最后更新: 2025年12月27日*
